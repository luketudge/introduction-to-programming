{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Example-program\" data-toc-modified-id=\"Example-program-1\">Example program</a></span></li><li><span><a href=\"#Built-in-tests\" data-toc-modified-id=\"Built-in-tests-2\">Built-in tests</a></span></li><li><span><a href=\"#Test-functions\" data-toc-modified-id=\"Test-functions-3\">Test functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Assertions\" data-toc-modified-id=\"Assertions-3.1\">Assertions</a></span></li></ul></li><li><span><a href=\"#Test-runners\" data-toc-modified-id=\"Test-runners-4\">Test runners</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "As you have probably noticed by now, it is easy to make mistakes when writing a computer program. Computers cannot easily guess what it is that we want of them, nor do they have any idea of what sort of things it is reasonable to want to do. So we must give a computer precise, [syntactically correct](extras/glossary.md#syntax) instructions that represent exactly what we want to do, and if we get this wrong, the computer will either be unable to do as we asked, in which case our program will break off with an [error](extras/glossary.md#error), or it will happily carry out the instructions we gave it, even when these are not actually the instructions that we wanted to give, and even if we have mistakenly instructed it to do something stupid or malicious such as emailing the contents of our downloads folder to our boss. It is therefore important to check our programs carefully for mistakes.\n",
    "\n",
    "Up until now, we have been able to check a program fairly easily by simply running it, if it is just a [script](extras/glossary.md#script), or importing it and then using its functions in the console if it is a [module](extras/glossary.md#module). But this sort of informal testing can only take us so far. Once we start writing programs that may take multiple different actions depending on user input, subtle mistakes may be difficult to detect in a quick informal test, because they only arise for some inputs and not others. For these reasons, most software developers test their programs systematically as they go along. Instead of testing a program manually, they write a second program whose only purpose is to test the main program. This test program tries out the main program with different inputs, and verifies that its behavior is as expected. In other words, a test program automates the process of testing the main program.\n",
    "\n",
    "Writing test programs can be tedious. As if we didn't already have enough work to do writing the main program, we now have to write another one that won't even be part of the finished product. It is tempting to dispense with testing, especially if a project is small. But we should not. Good tests act as a reasonable guarantee that our program functions correctly. And as the saying goes: Most customers prefer a product that actually works.\n",
    "\n",
    "## Example program\n",
    "\n",
    "In the spirit of the class so far, we won't actually be developing a product that any healthy customer would want to download. Instead, we have a program for producing [spoonerisms](https://en.wikipedia.org/wiki/Spoonerism). A spoonerism is a play on words in which the initial consonants (or groups of consonants) of two words are swapped. For example:\n",
    "\n",
    "* crushing blow → blushing crow\n",
    "* cosy nook → nosy cook\n",
    "* wasted term → tasted werm\n",
    "\n",
    "Since this lesson is about testing, we will look at the finished example program already. Our task will be to write some tests for the program. Let's import the program as [module](extras/glossary.md#module) and make some informal tests first. (If you need to refresh your understanding of modules and imports, take a look back at the [lesson on modules](modules.ipynb).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VOWELS',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'find_first_vowel',\n",
       " 'spoonerize']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spoonerisms\n",
    "\n",
    "dir(spoonerisms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main function is `spoonerize()`. We can look at its [docstring](extras/glossary.md#docstring) using the `help()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function spoonerize in module spoonerisms:\n",
      "\n",
      "spoonerize(wordpair)\n",
      "    Spoonerize a word pair.\n",
      "    \n",
      "    A spoonerism switches the initial consonant clusters of words.\n",
      "    \n",
      "    Example:\n",
      "        >>> spoonerize('smart fella')\n",
      "        'fart smella'\n",
      "    \n",
      "    Argument:\n",
      "        wordpair: A string containing exactly two words.\n",
      "    \n",
      "    Returns:\n",
      "        A string containing the spoonerized phrase.\n",
      "    \n",
      "    Raises ValueError:\n",
      "        If wordpair does not contain exactly two words.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(spoonerisms.spoonerize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the example input given in the docstring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fart smella'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spoonerisms.spoonerize('smart fella')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module is very slightly more complex than those we have encountered so far. In addition to the main function, it includes an additional 'helper function' that is [called](extras/glossary.md#call) from within the main function, and whose purpose is to find the location of the first vowel in a word (according to Python's zero-based [indexing](extras/glossary.md#index)). For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spoonerisms.find_first_vowel('smart')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This helper function in turn depends on a variable called `VOWELS`, a string containing the characters considered to be vowels. These could just have been defined within the `find_first_vowel()` function, but including them as a variable allows us later to add more vowels easily if we want to extend the module's capabilities.\n",
    "\n",
    "This is a good point to start writing tests; our program has gone beyond just a single function, and we might want to add to its capabilities in the future. Before we begin writing the tests, you might want to take a look at the module file [spoonerisms.py](examples/spoonerisms.py) and quickly assure yourself that you understand how it works.\n",
    "\n",
    "## Built-in tests\n",
    "\n",
    "The module in fact already incorporates one short test of its workings. It uses the `__name__` special variable to print out a result when the module is run as the main program. This is something that we learned about in the [lesson on modules](modules.ipynb#__name__). This sort of 'built-in test' can take us quite far, and is especially helpful early on in the development of a program. We will learn about a few ways in which a separate test program can be more convenient as development goes on. But first we need to cover the basics of test programs.\n",
    "\n",
    "## Test functions\n",
    "\n",
    "A test program goes in a separate file. This file usually has the same name as the file that it tests, but prefixed with *test_*. So in our case our test file will be called *test_spoonerisms.py*. Among the first things that the test program should do is import the module to be tested, since it will need to [call](extras/glossary.md#call) that module's functions and check their results. After importing the module to be tested, the test program defines functions, each of which tests one aspect of the module.\n",
    "\n",
    "Test functions look a little different from the functions we have written so far. They do not have any [return value](extras/glossary.md#return), and in most cases they have no input [arguments](extras/glossary.md#argument) either. In place of a return value, most test functions instead make an [assertion](extras/glossary.md#assertion).\n",
    "\n",
    "### Assertions\n",
    "\n",
    "What is an assertion? An assertion is yet another kind of [control statement](extras/glossary.md#control). You can think of it as a special kind of [condition](extras/glossary.md#condition), like in an `if` statement. Similar to an `if` statement, an assertion checks whether a particular condition is true or false, for example checking whether two things are equal using `==`. But unlike an `if` statement, we do not specify what happens when the condition is true and what happens when it is false. Instead, an assertion has fixed consequences: If the condition is true, nothing happens and the program continues as normal; if the condition is not true, an [exception](extras/glossary.md#exception) is raised.\n",
    "\n",
    "An assertion begins with the [keyword](extras/glossary.md#keyword) `assert`. Here is an example of an assertion that is true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 2 + 2 == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, nothing happens when Python runs this line. A true assertion just 'passes' and the Python interpreter moves on to the next line of the program.\n",
    "\n",
    "Compare this with what happens when an assertion is untrue. We get an `AssertionError`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-71c257695901>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 2 + 2 == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can therefore use an assertion to check whether the [return value](extras/glossary.md#return) of a function is as expected. For example for the `spoonerize()` function from our example module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = spoonerisms.spoonerize('smart fella')\n",
    "\n",
    "assert result == 'fart smella'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest test functions are just functions that contain one assertion. No input arguments or return value are needed; the function's only purpose is to alert us by raising an exception if things are not working as expected. Like test files, the names of test functions should be prefixed with `test_`, and then state what is being tested. Here is an example for our `spoonerize()` function, turning the assertion above into a test function.\n",
    "\n",
    "(If you need first to remind yourself of the syntax for functions, take a look back at the [lesson on functions](functions.ipynb#Defining-functions).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_spoonerize():\n",
    "    result = spoonerisms.spoonerize('smart fella')\n",
    "    assert result == 'fart smella'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we [call](extras/glossary.md#call) our test function, no exception is raised, confirming that the assertion was true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_spoonerize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the finished test file for our example module, [test_spoonerisms.py](examples/test_spoonerisms.py). You will see that it first imports the *spoonerisms* module, then defines several test functions like the one above. Each of these tests one aspect of the workings of the *spoonerisms* module. (There is one slightly different test function at the very end of the file. Ignore this for now; we will come to it in a moment.)\n",
    "\n",
    "If we would like to test any aspect of the *spoonerisms* module, we can import the test module and run its functions, confirming that no exceptions occur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import test_spoonerisms\n",
    "\n",
    "test_spoonerisms.test_find_first_vowel()\n",
    "test_spoonerisms.test_spoonerize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test runners\n",
    "\n",
    "Our solution so far isn't entirely satisfactory. We wanted to have an *automated* test of our module, so that we can for example quickly run the tests each time we make changes, and make sure that our changes haven't broken anything. Importing the test module and then running each of its tests individually is very laborious. Because automated testing is such a common task in programming, most programming languages provide tools for running multiple tests with a single command. These tools are sometimes termed 'test runners'.\n",
    "\n",
    "### pytest\n",
    "\n",
    "Python's built-in testing tools are provided in a module called `unittest` in the [standard library](standard_library.ipynb). However, there are also several excellent [third-party packages](standard_library.ipynb#Third-party-packages) that provide testing tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\r\n",
      "platform linux -- Python 3.6.9, pytest-5.3.2, py-1.8.1, pluggy-0.13.1\r\n",
      "rootdir: /home/lt/GitHub/introduction-to-programming/content/examples\r\n",
      "\u001b[1mcollecting ... \u001b[0m\u001b[1m\r",
      "collected 5 items                                                              \u001b[0m\r\n",
      "\r\n",
      "test_spoonerisms.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                [100%]\u001b[0m\r\n",
      "\r\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m5 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pytest test_spoonerisms.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
